name: Calibration Benchmarks

on:
  push:
    branches: [ master, main, develop ]
    paths:
      - 'stereo/src/calib3d.rs'
      - 'stereo/benches/**'
      - 'stereo/Cargo.toml'
      - '.github/workflows/benchmarks.yml'
  pull_request:
    branches: [ master, main ]
    paths:
      - 'stereo/src/calib3d.rs'
      - 'stereo/benches/**'
      - 'stereo/Cargo.toml'

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark:
    name: Run Calibration Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Install Rust toolchain
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        components: rustfmt, clippy

    - name: Cache cargo registry
      uses: actions/cache@v3
      with:
        path: ~/.cargo/registry
        key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}

    - name: Cache cargo index
      uses: actions/cache@v3
      with:
        path: ~/.cargo/git
        key: ${{ runner.os }}-cargo-git-${{ hashFiles('**/Cargo.lock') }}

    - name: Cache cargo build
      uses: actions/cache@v3
      with:
        path: target
        key: ${{ runner.os }}-cargo-build-target-${{ hashFiles('**/Cargo.lock') }}

    - name: Run benchmarks
      working-directory: stereo
      run: |
        cargo bench --bench calibration_benchmark -- --sample-size 20 --verbose
      timeout-minutes: 45

    - name: Save benchmark results
      if: always()
      working-directory: rust-cv-native
      run: |
        mkdir -p ci_artifacts
        ./scripts/save_benchmark_results.sh

    - name: Upload benchmark artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results-${{ github.run_id }}
        path: ci_artifacts/benchmarks/
        retention-days: 30

    - name: Comment PR with benchmark results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const summaryPath = 'ci_artifacts/benchmarks/summary_*.txt';
          const files = require('glob').sync(summaryPath);

          if (files.length > 0) {
            const summary = fs.readFileSync(files[0], 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '## ðŸ“Š Benchmark Results\n\n```\n' + summary + '\n```'
            });
          }

    - name: Publish benchmark report
      if: github.event_name == 'push' && github.ref == 'refs/heads/master'
      uses: actions/upload-artifact@v3
      with:
        name: criterion-html-report
        path: target/criterion/report/
        if-no-files-found: ignore

  # Optional: Compare benchmarks across commits
  compare-benchmarks:
    name: Compare Benchmark Results
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.event_name == 'pull_request'

    steps:
    - name: Download PR benchmark results
      uses: actions/download-artifact@v3
      with:
        name: benchmark-results-${{ github.run_id }}
        path: pr_results

    - name: Create comparison report
      run: |
        echo "## Benchmark Comparison"
        echo "Results from this PR:"
        if [ -f "pr_results/summary_*.txt" ]; then
          head -20 pr_results/summary_*.txt
        else
          echo "No benchmark results found"
        fi
